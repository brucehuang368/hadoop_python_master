## 准备工作 
### 1、 修改hostname
```
shell 输入命令：
hostname gx.h12
```

### 2、 修改hosts文件
```
vi /etc/hosts
在文件顶行增加
192.168.221.128 gx.h12
如果有其他机器，继续增加，如：
192.168.221.129 gx.h13
192.168.221.130 gx.h14
...
```
### 3、 配置机器免秘钥访问
```
切换root用户
su root
生成公钥
ssh-keygen -t rsa
输入以上命令后，会有提示，一直按回车键确定
继续以下命令
cat ~/.ssh/id_dsa.pub >> ~/.ssh/authorized_keys
chmod 700 ~/.ssh
chmod 600 ~/.ssh/*
关闭防火墙
service iptables off 或 service iptables stop
测试：
ssh root@127.0.0.1
如果提示机器不存在know_host文件里面，是否继续，请输入yes
如果不用输入密码就能登录了，就代表配置成功
```

##　安装java

```
进入oracle官网，下载linux的java1.7 jdk 包 jdk-7u15-linux-x64.gz
解压压缩包
tar -zxvf   jdk-7u15-linux-x64.gz
把产生的文件夹移到根目录
mv  jdk-7u15-linux-x64 /jdk
配置环境变量
echo 'export JAVA_HOME=/jdk' >> /etc/profile
echo 'export PATH=$JAVA_HOME/bin:$PATH' >>  /etc/profile
source /etc/profile
输入 java --version 如果有1.7版本号，则代表成功
```
##  安装hadoop

```
从apache官网下载hadoop 2.7版本
解压压缩包 hadoop-2.7.3.tar.gz
tar -zxvf hadoop-2.7.3.tar.gz
mv hadoop-2.7.3 /opt/hadoop
配置环境变量
echo 'export HADOOP_HOME=/opt/hadoop' >> /etc/profile
echo 'export PATH=$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$PATH' >>  /etc/profile
source /etc/profile
```

```
修改 hadoop core-site.xml配置文件
vi $HADDOOP_HOME/etc/core-site.xml
<configuration>
<property>
 <name>fs.default.name</name>
  <value>hdfs://gx.h12:9210</value>
</property>
<property>
  <name>hadoop.tmp.dir</name>
 <value>/var/hadoop/tmp</value>
</property>
</configuration>
```

```
修改 hadoop hdfs-site.xml配置文件
vi $HADDOOP_HOME/etc/hdfs-site.xml

<configuration>
<property>
<name>dfs.data.dir</name>
<value>/var/hadoop/data</value>
</property>
<property>
<name>dfs.name.dir</name>
<value>/var/hadoop/name</value>
</property>
<property>
  <name>dfs.replication</name>
  <value>1</vaue>
</property>
</configuration>

保存退出建立以下文件夹
mkdir /var/hadoop
```
```
修改 hadoop mapred-site.xml配置文件
vi $HADDOOP_HOME/etc/mapred-site.xml
<configuration>
<property>
<name>mapreduce.framework.name</name>
<value>yarn</value>
</property>

<property>
<name>mapreduce.jobhistory.address</name>
<value>gx.h12:10020</value>
</property>

<property>
<name>mapreduce.jobhistory.webapp.address</name>
<value>gx.h12:19888</value>
</property>
</configuration>

```

```
修改 hadoop yarn-site.xml配置文件
vi $HADDOOP_HOME/etc/yarn-site.xml
<configuration>
 <property>
   <name>yarn.resourcemanager.connect.retry-interval.ms</name>
   <value>2000</value>
 </property>
 </configuration>

```

```
修改 hadoop hadoop-env.sh配置文件
vi $HADDOOP_HOME/etc/hadoop-env.sh
export JAVA_HOME=/opt/jdk
```

```
修改 hadoop slaves配置文件
vi $HADDOOP_HOME/etc/slaves
输入 gx.h12 机器名
```
```
格式化namenode 
hadoop namenode -format
如果没有报错，则配置成功
启动hadoop
start-all.sh
输入jps查看hadoop 进程
36727 ResourceManager
36726 SecondaryNameNode
36742 DataNode
36745 NameNode

```

##  安装zookeeper
```
从apache官网下载zookeeper 版本3.4.6
解压压缩包 zookeeper-3.4.6.tar.gz
tar -zxvf zookeeper-3.4.6.tar.gz
mv  zookeeper-3.4.6 /opt/zookeeper
配置环境变量
echo 'export ZOOKEEPER_HOME=/opt/zookeeper' >> /etc/profile
echo 'export PATH=$ZOOKEEPER_HOME/bin:$PATH' >>  /etc/profile
source /etc/profile
创建文件夹,存放zookeeper数据
mkdir /var/zookeeper/data
创建文件夹,存放zookeeper日志
mkdir /var/zookeeper/logs
```
```
配置zookeeper
cat $ZOOKEEPER_HOME/conf/zoosample.cfg >  $ZOOKEEPER_HOME/conf/zoo.cfg
vi  $ZOOKEEPER_HOME/conf/zoo.cfg

tickTime=2000    
dataDir=/var/zookeeper/data    
dataLogDir=/var/zookeeper/logs    
clientPort=2181
server.1=gx.h12:8880:7770 
保存退出
vi /var/zookeeper/data/myid
输入 1
保存退出

```
```
运行zookeeper
zkServer.sh start
这是 zkServer.sh status查看是否正常运行
```

##  安装hbase
```
从apache官网下载hbase 版本3.4.6
解压压缩包 hbase-1.3.0-bin.tar.gz
tar -zxvf hbase-1.3.0-bin.tar.gz
mv hbase-1.3.0-bin /opt/hbase
配置环境变量
echo 'export HBASE_HOME=/opt/hbase' >> /etc/profile
echo 'export PATH=$HBASE_HOME/bin:$PATH' >>  /etc/profile
source /etc/profile
```
```
配置hbase-site.xml
vi $HBASE_HONE/conf/hbase-site.xml
<configuration>
<property>
<name>hbase.rootdir</name>
<value>hdfs://gx.h12:9210/hbase</value>
</property>
<property>
<name>hbase.regionserver.regionSplitLimit</name>
<value>1</value>
</property>
<property>
<name>hbase.cluster.distributed</name>
<value>true</value>
</property>
<property>
<name>hbase.master</name>
<value>hdfs://gx.h12:60000</value>
</property>
<property>
<name>hbase.zookeeper.quorum</name>
<value>gx.h12:2181</value>
</property>
<property>
<name>hbase.zookeeper.property.dataDir</name>
<value>/dev/zookeeper/data</value>
</property>
<property>
<name>zookeeper.session.timeout</name>
<value>90000</value>
</property>
</configuration>

```
```
配置hbase-env.sh
vi $HBASE_HONE/conf/hbase-env.sh
export JAVA_HOME=/jdk
export HBASE_MANAGES_ZK=false
```

```
启动hbase 
start-hbase.sh
输入jps查看进程确保有：
HMaster
HRegionServer
```
##  安装storm

```
从apache官网下载hbase 版本 0.9.4
解压压缩包 apache-storm-0.9.4.tar.gz
tar -zxvf apache-storm-0.9.4.tar.gz
mv apache-storm-1.0.1 /opt/storm
配置环境变量
echo 'export STORM_HOME=/opt/storm' >> /etc/profile
echo 'export PATH=$STORM_HOME/bin:$PATH' >>  /etc/profile
source /etc/profile
```
```
配置storm 
vi $STORM_HOME/conf/storm.yarml
storm.zookeeper.servers:
     - "gx.h12"
nimbus.host: "gx.h12"
supervisor.slots.ports:
   - 6700
   - 6701
storm.local.dir: "/var/storm"
ui.port: 8887
保存退出
创建文件夹
mkdir /var/storm
```

```
启动   nimbus
输入命令 storm nimbus
启动  supervisor
输入命令 storm supervisor
启动 ui
输入命令 storm ui
输入jps查看进程
40074 core
43205 nimbus
60674 RunJar
43665 supervisor

```

##  安装kafka
```
从apache官网下载 kafka_2.10-0.10.2.0.tgz
解压压缩包 kafka_2.10-0.10.2.0.tgz
tar -jxvf kafka_2.10-0.10.2.0.tgz
mv kafka_2.10-0.10.2.0 /opt/kafka
配置环境变量
echo 'export KAFKA_HOME=/opt/kafka' >> /etc/profile
echo 'export PATH=$KAFKA_HOME/bin:$PATH' >>  /etc/profile
source /etc/profile
```
```
配置kafka
vi $KAFKA_HOME/config/zookeeper.properties

dataDir=/root/software/zookeeper/data
# the port at which the clients will connect
clientPort=2181
# disable the per-ip limit on the number of connections since this is a non-production config
maxClientCnxns=0

vi $KAFKA_HOME/config/producer.properties
bootstrap.servers=gx.h12:9092


```
```
启动kafka
$KAFKA_HOME/bin/kafka-server-start.sh $KAFKA_HOME/config/server.properties
```
##  安装hive
```
从apache官网下载 apache-hive-2.1.1-bin.tar.gz
解压压缩包 apache-hive-2.1.1-bin.tar.gz
tar -zxvf kafka_2.10-0.10.2.0.tgz
mv apache-hive-2.1.1-bin /opt/hive
配置环境变量
echo 'export HIVE_HOME=/opt/kafka' >> /etc/profile
echo 'export PATH=$HIVE_HOME/bin:$PATH' >>  /etc/profile
source /etc/profile
创建文件夹
mkdir $HIVE_HOME/warehome
连接hbase
进入  $HIVE_HOME/warehome
输入命令 hive --auxpath $HIVE_HOME/lib/hive-hbase-handler-1.2.1.jar,$HIVE_HOME/lib/zookeeper-3.4.6.jar,$HIVE_HOME/lib/guava-14.0.1.jar --hiveconf hbase.zookeeper.quorm=gx.h12
set hive.hbase.wal.enabled=true;
exit;退出

输入命令 hiveserver2启动服务端

测试：
通过 beeline用jdbc连接
beeline -u jdbc:hive2://gx.h12:10000/default -n root 
```



